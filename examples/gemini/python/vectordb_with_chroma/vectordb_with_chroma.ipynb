{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsVPnR8VbXE6"
      },
      "source": [
        "# Document Q&A with ChromaDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awKO767lQIWh"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/examples/gemini/python/vectordb_with_chroma/vectordb_with_chroma.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/examples/gemini/python/vectordb_with_chroma/vectordb_with_chroma.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtwZ8DZGJfUv"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial demonstrates how to use the Gemini API to create a vector database and retrieve answers to questions from the database. Moreover, you will use [ChromaDB](https://docs.trychroma.com/){:.external}, an open-source Python tool that creates embedding databases. ChromaDB allows you to:\n",
        "\n",
        "* Store embeddings as well as their metadata\n",
        "* Embed documents and queries\n",
        "* Search through the database of embeddings\n",
        "\n",
        "In this tutorial, you'll use embeddings to retrieve an answer from a database of vectors created with ChromaDB.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "You can run this quickstart in Google Colab.\n",
        "\n",
        "To complete this quickstart on your own development environment, ensure that your environment meets the following requirements:\n",
        "\n",
        "-  Python 3.9+\n",
        "-  An installation of `jupyter` to run the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akuOzK4dJl3j"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, download and install ChromaDB and the Gemini API Python library."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-ai-generativelanguage==0.6.15\n"
      ],
      "metadata": {
        "id": "MtlZpVnh5_cn",
        "outputId": "4b034b91-1f88-4ed9-dccf-da116fa15f48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (0.6.15)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (2.25.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (1.72.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage==0.6.15) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage==0.6.15) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage==0.6.15) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage==0.6.15) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JbXe7Oodc5dP"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sNCv-cJPLOZ2",
        "outputId": "dde59b88-60a1-4f43-ac69-cc8f120abd18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwmKt115PxK8"
      },
      "source": [
        "Then import the modules you'll use in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "muuhsDmmKdHi"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "import chromadb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import Markdown\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6tZGHUDOCFW"
      },
      "source": [
        "### Grab an API Key\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n",
        "\n",
        "In Colab, add the key to the secrets manager under the \"ğŸ”‘\" in the left panel. Give it the name `API_KEY`.\n",
        "\n",
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "* Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n",
        "* Pass the key to `genai.configure(api_key=...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JoCFT6SaiCBX"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('API_KEY')` to fetch an environment variable.\n",
        "API_KEY=\"AIzaSyCTQ3T6iqXECoROGGQri9-H2scItu_-n68\"\n",
        "\n",
        "genai.configure(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fegnGFpMS4AI"
      },
      "source": [
        "Key Point: Next, you will choose a model. Any embedding model will work for this tutorial, but for real applications it's important to choose a specific model and stick with it. The outputs of different models are not compatible with each other.\n",
        "\n",
        "**Note**: At this time, the Gemini API is [only available in certain regions](https://ai.google.dev/available_regions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Km5d13_FS2Q_",
        "outputId": "68aa6cf9-8270-45ee-b0d7-86e6384114c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'embedContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XWKXoXwOGxS"
      },
      "source": [
        "### Data\n",
        "\n",
        "Here is a small set of documents you will use to create an embedding database:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MDvKUH2B4jML",
        "outputId": "326bbc2d-d021-4dc3-f04a-719125d47579",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/vectorDB\"  # Path to your Excel files\n",
        "documents = []\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".xlsx\"):\n",
        "        path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Read the Excel file\n",
        "        df = pd.read_excel(path, header=None)  # or specify sheet name\n",
        "        text = \"\\n\".join(df.astype(str).stack().tolist())  # Flatten and join all cells as string\n",
        "        documents.append(text)\n",
        "\n",
        "print(f\"Loaded {len(documents)} documents from Excel files.\")\n"
      ],
      "metadata": {
        "id": "6PLPQ1MP4cDQ",
        "outputId": "909d8d78-e68b-45b6-ebbe-d5940f364538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3 documents from Excel files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EoMw0GNi8Lo3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDzxArLeOexD"
      },
      "source": [
        "## Creating the embedding database with ChromaDB\n",
        "\n",
        "You will create a [custom function](https://docs.trychroma.com/embeddings#custom-embedding-functions){:.external} for performing embedding using the Gemini API. By inputting a set of documents into this custom function, you will receive vectors, or embeddings of the documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoHhS32txd_r"
      },
      "source": [
        "### API changes to Embeddings with model embedding-001\n",
        "\n",
        "For the new embeddings model, embedding-001, there is a new task type parameter and the optional title (only valid with task_type=`RETRIEVAL_DOCUMENT`).\n",
        "\n",
        "These new parameters apply only to the newest embeddings models.The task types are:\n",
        "\n",
        "Task Type | Description\n",
        "---       | ---\n",
        "RETRIEVAL_QUERY\t| Specifies the given text is a query in a search/retrieval setting.\n",
        "RETRIEVAL_DOCUMENT | Specifies the given text is a document in a search/retrieval setting.\n",
        "SEMANTIC_SIMILARITY\t| Specifies the given text will be used for Semantic Textual Similarity (STS).\n",
        "CLASSIFICATION\t| Specifies that the embeddings will be used for classification.\n",
        "CLUSTERING\t| Specifies that the embeddings will be used for clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mF7Uu1kCQsT0"
      },
      "outputs": [],
      "source": [
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "  def __call__(self, input: Documents) -> Embeddings:\n",
        "    model = 'models/embedding-001'\n",
        "    title = \"Custom query\"\n",
        "    return genai.embed_content(model=model,\n",
        "                                content=input,\n",
        "                                task_type=\"retrieval_document\",\n",
        "                                title=title)[\"embedding\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrDWLyopPNBf"
      },
      "source": [
        "Now you will create the vector database. In the `create_chroma_db` function, you will instantiate a [Chroma client](https://docs.trychroma.com/getting-started){:.external}. From there, you will create a collection, which is where you store your embeddings, documents, and any metadata. Note that the embedding function from above is passed as an argument to the `create_collection`.\n",
        "\n",
        "Next, you use the `add` method to add the documents to the collection."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def create_chroma_db(documents, name, batch_size=5000, drive_path='/content/drive/MyDrive/chroma_store'):\n",
        "    if not documents:\n",
        "        raise ValueError(\"The 'documents' list is empty.\")\n",
        "\n",
        "    # Step 1: Mount Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Step 2: Copy from Drive if exists\n",
        "    local_path = \"./chroma_store\"\n",
        "    if os.path.exists(drive_path):\n",
        "        if not os.path.exists(local_path):\n",
        "            shutil.copytree(drive_path, local_path)\n",
        "            print(\"Loaded Chroma DB from Drive.\")\n",
        "\n",
        "    # Step 3: Use PersistentClient\n",
        "    chroma_client = chromadb.PersistentClient(path=local_path)\n",
        "\n",
        "    existing_collections = [col.name for col in chroma_client.list_collections()]\n",
        "    if name in existing_collections:\n",
        "        db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
        "        print(f\"Loaded existing collection: {name}\")\n",
        "    else:\n",
        "        db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
        "        print(f\"Created new collection: {name}\")\n",
        "\n",
        "        splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
        "        all_chunks = []\n",
        "        all_ids = []\n",
        "\n",
        "        for i, doc in enumerate(documents):\n",
        "            chunks = splitter.split_text(doc)\n",
        "            all_chunks.extend(chunks)\n",
        "            all_ids.extend([f\"{i}_{j}\" for j in range(len(chunks))])\n",
        "\n",
        "        # Add in batches\n",
        "        for start in range(0, len(all_chunks), batch_size):\n",
        "            end = start + batch_size\n",
        "            batch_chunks = all_chunks[start:end]\n",
        "            batch_ids = all_ids[start:end]\n",
        "            db.add(documents=batch_chunks, ids=batch_ids)\n",
        "            print(f\"Added batch {start} to {end} to collection '{name}'.\")\n",
        "\n",
        "        # Step 4: Save to Drive\n",
        "        if os.path.exists(drive_path):\n",
        "            shutil.rmtree(drive_path)\n",
        "        shutil.copytree(local_path, drive_path)\n",
        "        print(\"Saved Chroma DB to Drive.\")\n",
        "\n",
        "    return db\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k37Ep8N9wrdg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Call the function to create and assign the db variable\n",
        "db = create_chroma_db(documents, \"my_document_collection\")"
      ],
      "metadata": {
        "id": "EvvHQcGBxiSI",
        "outputId": "9d5d1438-879d-4260-f1f6-42177c0b2056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1525252620>:27: DeprecationWarning: The class GeminiEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
            "  db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new collection: my_document_collection\n",
            "Added batch 0 to 5000 to collection 'my_document_collection'.\n",
            "Added batch 5000 to 10000 to collection 'my_document_collection'.\n",
            "Added batch 10000 to 15000 to collection 'my_document_collection'.\n",
            "Added batch 15000 to 20000 to collection 'my_document_collection'.\n",
            "Added batch 20000 to 25000 to collection 'my_document_collection'.\n",
            "Added batch 25000 to 30000 to collection 'my_document_collection'.\n",
            "Added batch 30000 to 35000 to collection 'my_document_collection'.\n",
            "Added batch 35000 to 40000 to collection 'my_document_collection'.\n",
            "Saved Chroma DB to Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QbwFgfXp-fL"
      },
      "source": [
        "Confirm that the data was inserted by looking at the database:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu5zRErgsQ8u"
      },
      "source": [
        "## Getting the relevant document\n",
        "\n",
        "`db` is a Chroma collection object. You can call `query` on it to perform a nearest neighbors search to find similar embeddings or documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gQdJMbTSLtKE"
      },
      "outputs": [],
      "source": [
        "def get_relevant_passage(query, db):\n",
        "  passage = db.query(query_texts=[query], n_results=1)['documents'][0][0]\n",
        "  return passage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nWYXXKJ6t6Hy",
        "outputId": "47473100-b618-4678-c121-2d3926bd85b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'query' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2165686536>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform embedding search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpassage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_relevant_passage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'query' is not defined"
          ]
        }
      ],
      "source": [
        "# Perform embedding search\n",
        "passage = get_relevant_passage(query, db)\n",
        "Markdown(passage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8PNRMpOQkm5"
      },
      "source": [
        "Now that you have found the relevant passage in your set of documents, you can use it make a prompt to pass into the Gemini API."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a few records (documents) from the collection\n",
        "peek_data = db.peek(3)\n",
        "print(peek_data)\n"
      ],
      "metadata": {
        "id": "YfX7KLuJA7f2",
        "outputId": "55296f65-669a-4917-87f3-ad7abc4bc9a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': ['0_0', '0_1', '0_2'], 'embeddings': array([[ 0.04806398, -0.02096214, -0.06218296, ...,  0.03389169,\n",
            "        -0.02237787, -0.01042494],\n",
            "       [ 0.04533244, -0.01592427, -0.0636674 , ...,  0.01667201,\n",
            "        -0.03433314,  0.01253321],\n",
            "       [ 0.05976871, -0.02252777, -0.07497181, ...,  0.02067008,\n",
            "        -0.03486569,  0.00891464]]), 'documents': ['ì¢…ëª©ì½”ë“œ\\níšŒì‚¬ëª…\\nì‹œì¥êµ¬ë¶„\\nì—…ì¢…\\nì—…ì¢…ëª…\\ní•­ëª©ì½”ë“œ\\nê²°ì‚°ê¸°ì¤€ì¼\\ní•­ëª©ëª…\\në‹¹ê¸°\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\ndart_NonOperatingProfitLoss\\n2024-12-31 00:00:00\\n      ê¸°íƒ€ìˆœì†ìµ\\n160081113000\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\ndart_OperatingIncomeLoss\\n2024-12-31 00:00:00\\n      ì˜ì—…ì´ìµ(ì†ì‹¤)\\n136262575000\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\ndart_BasicEarningsLossPerSharePreferredStock\\n2024-12-31 00:00:00\\n         ìš°ì„ ì£¼ê¸°ë³¸ì£¼ë‹¹ìˆœì´ìµ(ì†ì‹¤)\\n6767\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\ndart_DilutedEarningsLossPerSharePreferredStock\\n2024-12-31 00:00:00\\n         ìš°ì„ ì£¼í¬ì„ì£¼ë‹¹ìˆœì´ìµ(ì†ì‹¤)\\n6767', '2024-12-31 00:00:00\\n         ìš°ì„ ì£¼í¬ì„ì£¼ë‹¹ìˆœì´ìµ(ì†ì‹¤)\\n6767\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\nentity00148540_BasicEarningsLossPerShareOfNewPreferenceSharesOfEarningsPerShareOfEarningsPerShareAbstract\\n2024-12-31 00:00:00\\n         ì‹ í˜•ìš°ì„ ì£¼ ê¸°ë³¸ì£¼ë‹¹ì´ìµ\\n6717\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\nentity00148540_DilutedEarningsLossPerShareOfNewPreferenceSharesOfEarningsPerShareOfEarningsPerShareAbstract\\n2024-12-31 00:00:00\\n         ì‹ í˜•ìš°ì„ ì£¼ í¬ì„ì£¼ë‹¹ì´ìµ\\n6717\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\nifrs-full_BasicEarningsLossPerShare', '649\\nê¸°íƒ€ ê¸ˆìœµì—…\\nifrs-full_BasicEarningsLossPerShare\\n2024-12-31 00:00:00\\n         ë³´í†µì£¼ê¸°ë³¸ì£¼ë‹¹ì´ìµ(ì†ì‹¤)\\n6717\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\nifrs-full_DilutedEarningsLossPerShare\\n2024-12-31 00:00:00\\n         ë³´í†µì£¼í¬ì„ì£¼ë‹¹ì´ìµ(ì†ì‹¤)\\n6717\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\nifrs-full_FinanceCosts\\n2024-12-31 00:00:00\\n      ê¸ˆìœµë¹„ìš©\\n12115119000\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\nifrs-full_FinanceIncome\\n2024-12-31 00:00:00\\n      ê¸ˆìœµìˆ˜ìµ\\n1715055000\\n[001040]\\nCJ\\nìœ ê°€ì¦ê¶Œì‹œì¥ìƒì¥ë²•ì¸\\n649\\nê¸°íƒ€ ê¸ˆìœµì—…\\nifrs-full_IncomeTaxExpenseContinuingOperations'], 'uris': None, 'included': ['metadatas', 'documents', 'embeddings'], 'data': None, 'metadatas': [None, None, None]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Qkhu4iazLy3G"
      },
      "outputs": [],
      "source": [
        "def make_prompt(query, relevant_passage):\n",
        "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
        "  prompt = (\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
        "  Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
        "  However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
        "  strike a friendly and converstional tone. \\\n",
        "  If the passage is irrelevant to the answer, you may ignore it.\n",
        "  QUESTION: '{query}'\n",
        "  PASSAGE: '{relevant_passage}'\n",
        "\n",
        "    ANSWER:\n",
        "  \"\"\").format(query=query, relevant_passage=escaped)\n",
        "\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMEjbz4EswQ6"
      },
      "source": [
        "Pass a query to the prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b6_Y-GOymaXu",
        "outputId": "1effe350-ee07-420c-86b8-7b3027f6f746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'passage' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1870471175>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ë“€ì¼ë°”ì´ì˜¤ ë‹¹ê¸°?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'passage' is not defined"
          ]
        }
      ],
      "source": [
        "query = \"ë“€ì¼ë°”ì´ì˜¤ ë‹¹ê¸°?\"\n",
        "prompt = make_prompt(query, passage)\n",
        "Markdown(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRy6yXzcPxLB"
      },
      "source": [
        "Now use the `generate_content` method to to generate a response from the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThTbjAJ7eGP5"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "To learn more about how you can use the embeddings, check out the [examples](https://ai.google.dev/examples?keywords=embed) available. To learn how to use other services in the Gemini API, visit the [Python quickstart](https://ai.google.dev/gemini-api/docs/get-started/python)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "vectordb_with_chroma.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}